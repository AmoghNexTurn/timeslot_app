{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727f62c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "  os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter API key for Groq: \")\n",
    "\n",
    "\n",
    "llm = init_chat_model(\"qwen/qwen3-32b\", model_provider=\"groq\", temperature=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0dbc9d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the weather in sf', additional_kwargs={}, response_metadata={}, id='95d891b3-0536-4ff0-a3fd-bc04ae82a064'),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': \"Okay, the user is asking for the weather in SF. I need to figure out which function to use. The available tool is get_weather, which requires a city parameter. SF is the abbreviation for San Francisco. So I should call get_weather with the city set to San Francisco. Let me make sure that's the correct parameter. Yep, the function takes a city string. I'll format the tool call accordingly.\\n\", 'tool_calls': [{'id': '7t5m992cw', 'function': {'arguments': '{\"city\":\"San Francisco\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 109, 'prompt_tokens': 158, 'total_tokens': 267, 'completion_time': 0.214759423, 'prompt_time': 0.006093257, 'queue_time': 0.047341373, 'total_time': 0.22085268}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--0a75c89d-a0db-4c2a-a6ad-3706a798e059-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': '7t5m992cw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 158, 'output_tokens': 109, 'total_tokens': 267}),\n",
       "  ToolMessage(content=\"It's always sunny in San Francisco!\", name='get_weather', id='a1ba1bb6-d837-4542-802e-6c12ac4ada5d', tool_call_id='7t5m992cw'),\n",
       "  AIMessage(content=\"The weather in San Francisco is sunny! ðŸ˜Š Let me know if you'd like to check another location or need more details.\", additional_kwargs={'reasoning_content': \"Okay, the user asked about the weather in SF, and I called the get_weather function with San Francisco as the city. The response came back saying it's always sunny there. Now I need to relay that information back to the user in a friendly way.\\n\\nFirst, I should confirm the city they asked about to make sure there's no confusion. Then, present the weather information clearly. Since the response from the tool is straightforward, I don't need to add much extra info. Maybe add a smiley emoji to keep the tone positive. Also, check if they need anything else, like more details or another query. Keep it concise and helpful.\\n\"}, response_metadata={'token_usage': {'completion_tokens': 162, 'prompt_tokens': 199, 'total_tokens': 361, 'completion_time': 0.347293202, 'prompt_time': 0.009724441, 'queue_time': 0.107593978, 'total_time': 0.357017643}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ca5c9620-3678-47a9-929d-9acead4f7c15-0', usage_metadata={'input_tokens': 199, 'output_tokens': 162, 'total_tokens': 361})]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather],\n",
    "    prompt=\"You are a helpful assistant\"\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e80b5c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3eeecc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'pmty0he2c', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'p7z7s6ntm', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "\n",
    "messages = [SystemMessage(content=\"Analyse the query carefully and figure out which tools to use. You HAVE to use the provided tools if you can\")]+[HumanMessage(query)]\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "\n",
    "print(ai_msg.tool_calls)\n",
    "\n",
    "messages.append(ai_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e90bb716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Analyse the query carefully and figure out which tools to use. You HAVE to use the provided tools if you can', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is 3 * 12? Also, what is 11 + 49?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'reasoning_content': \"Okay, let's see. The user is asking two questions here. First, they want to know 3 multiplied by 12, and second, 11 plus 49. I need to figure out which functions to use for each part.\\n\\nLooking at the tools provided, there's the 'multiply' function for the first part and 'add' for the second. The multiply function takes two integers, a and b, so I'll use that for 3 and 12. Then the add function takes two integers as well, so that's for 11 and 49. \\n\\nI should make sure the parameters are correct. For the first tool call, the name should be 'multiply' with a=3 and b=12. The second tool call is 'add' with a=11 and b=49. Let me double-check the parameters to make sure they're required and the types are integers. Yep, both functions require a and b as integers. \\n\\nNo other functions are available, so these are the right choices. I need to output each tool call in the specified JSON format within the tool_call tags. Alright, that should cover both parts of the user's query.\\n\", 'tool_calls': [{'id': 'pmty0he2c', 'function': {'arguments': '{\"a\":3,\"b\":12}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'p7z7s6ntm', 'function': {'arguments': '{\"a\":11,\"b\":49}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 306, 'prompt_tokens': 266, 'total_tokens': 572, 'completion_time': 0.538700749, 'prompt_time': 0.011158476, 'queue_time': 0.055602414, 'total_time': 0.549859225}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--f3b666fd-650f-44da-8789-6ca7a579ecfb-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'pmty0he2c', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'p7z7s6ntm', 'type': 'tool_call'}], usage_metadata={'input_tokens': 266, 'output_tokens': 306, 'total_tokens': 572}),\n",
       " ToolMessage(content='36', name='multiply', tool_call_id='pmty0he2c'),\n",
       " ToolMessage(content='60', name='add', tool_call_id='p7z7s6ntm')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "messages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1628f5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The result of 3 * 12 is **36**, and the result of 11 + 49 is **60**.', additional_kwargs={'reasoning_content': 'Okay, let\\'s see. The user asked two questions: 3 multiplied by 12 and 11 plus 49. I need to use the provided functions to get the answers.\\n\\nFirst, for the multiplication part, the function is called \"multiply\" and takes two integers. The parameters a and b are 3 and 12. So I\\'ll call multiply(3, 12). The response from the tool was 36. That\\'s correct because 3 times 12 is indeed 36.\\n\\nNext, the addition part. The function here is \"add\" with a and b as 11 and 49. Adding those together, 11 + 49 equals 60. The tool\\'s response was 60, which matches my calculation.\\n\\nNow, I need to present both answers clearly. The user probably wants a straightforward answer without any extra details. Just the results of both operations. I should format it in a way that\\'s easy to read, maybe using bullet points or a simple sentence structure. Let me make sure there are no calculation errors. 3*12 is 36 and 11+49 is 60. Yep, all good. Time to put it all together.\\n'}, response_metadata={'token_usage': {'completion_tokens': 297, 'prompt_tokens': 349, 'total_tokens': 646, 'completion_time': 0.93337701, 'prompt_time': 0.015860652, 'queue_time': 0.085135298, 'total_time': 0.949237662}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--6e9f8eaf-9845-42b8-9480-3bd6e57c1fb4-0', usage_metadata={'input_tokens': 349, 'output_tokens': 297, 'total_tokens': 646})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeslot_app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
